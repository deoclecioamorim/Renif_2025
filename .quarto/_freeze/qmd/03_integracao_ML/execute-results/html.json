{
  "hash": "49d8b7f4a9f960a69cfc812703dc22c6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Integração com modelos de Machine Learning\"\nauthor: \"Deoclecio J. Amorim (CENA), João Paulo Sena-Souza (Unimontes) e Paulo José Duarte Neto (UFRPE)\"\nformat:\n  html:\n    page-layout: full       # usa toda a largura da janela\n    toc: true\n    toc-location: left\n    fig-width: 5\n    fig-height: 5\nknitr: \n  opts_chunk: \n    fig-align: center\n---\n\n\n\n# Introdução \n\nNeste módulo, aprenderemos a integrar dados geoespaciais com modelos de **Machine Learning** para gerar mapas preditivos (isoscapes).\n\nO objetivo aqui é mostrar como **aprendizado de máquina, como Random Forest**, pode ser usado para mais eficientes para prever padrões espaciais de isótopos.\n\nDurante o exercício, você irá:\n\n- Preparar dados de amostras combinados com covariáveis ambientais;\n- Ajustar modelos de machine learning, por exemplo, o modelo **Random Forest**;\n- Avaliar a importância das variáveis no modelo;\n- Gerar um **mapa preditivo espacial** do δ13C.\n\n\n\n---\n\n\n# 1. Configuração inicial\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Limpar área de trabalho\nrm(list = ls())      \ngc(reset = TRUE)     \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          used (Mb) gc trigger (Mb) max used (Mb)\nNcells  608307 32.5    1384552   74   608307 32.5\nVcells 1112346  8.5    8388608   64  1112346  8.5\n```\n\n\n:::\n\n```{.r .cell-code}\ngraphics.off()       \n\n#Pacotes necessários\nif(!require(readxl))install.packages(\"readxl\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: readxl\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(tidyverse))install.packages(\"tidyverse\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: tidyverse\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(terra))install.packages(\"terra\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: terra\nterra 1.8.50\n\nAnexando pacote: 'terra'\n\nO seguinte objeto é mascarado por 'package:tidyr':\n\n    extract\n\nO seguinte objeto é mascarado por 'package:knitr':\n\n    spin\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(geodata))install.packages(\"geodata\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: geodata\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(geobr))install.packages(\"geobr\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: geobr\nCarregando namespace exigido: sf\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(sf))install.packages(\"sf\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: sf\nLinking to GEOS 3.13.1, GDAL 3.10.2, PROJ 9.5.1; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(sp))install.packages(\"sp\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: sp\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(here))install.packages(\"here\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: here\nhere() starts at C:/Users/DELL/OneDrive/Documentos/Cena/Cursos_Extensao_CENA/renif_2025\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(caret))install.packages(\"caret\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: caret\nCarregando pacotes exigidos: lattice\n\nAnexando pacote: 'caret'\n\nO seguinte objeto é mascarado por 'package:purrr':\n\n    lift\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(randomForest))install.packages(\"randomForest\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: randomForest\nrandomForest 4.7-1.2\nType rfNews() to see new features/changes/bug fixes.\n\nAnexando pacote: 'randomForest'\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    combine\n\nO seguinte objeto é mascarado por 'package:ggplot2':\n\n    margin\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(ranger))install.packages(\"ranger\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: ranger\n\nAnexando pacote: 'ranger'\n\nO seguinte objeto é mascarado por 'package:randomForest':\n\n    importance\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require(VSURF))install.packages(\"VSURF\", dep = TRUE, quiet = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCarregando pacotes exigidos: VSURF\n```\n\n\n:::\n:::\n\n\n# 2. Reprodutibilidade \n\nA reprodutibilidade é um princípio fundamental da ciência, pois garante que os resultados obtidos em uma pesquisa possam ser verificados e replicados por outros pesquisadores ou em futuras análises. Assegurar que os procedimentos sejam replicáveis aumenta a transparência, a credibilidade dos dados e fortalece a robustez das conclusões.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset_reproducibility <- function(seed = 1350) {\n  set.seed(seed)\n  RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", sample.kind = \"Rounding\")\n}\n\n# Fixando a reprodutibilidade\nset_reproducibility()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", :\nnon-uniform 'Rounding' sampler used\n```\n\n\n:::\n:::\n\n\n# 3. Carregando o conjunto de dados \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\namz_var_clim <- readxl::read_excel(here::here(\"dados\", \"madeira_amz_var_clim.xlsx\"), sheet = 1)\nhead(amz_var_clim) #leitura das primeiras 6 linhas\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 12\n      x      y Site     Family d13C_wood elev_mean prec_mean srad_mean tavg_mean\n  <dbl>  <dbl> <chr>    <chr>      <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n1 -67.0 -0.121 São Gab… Myris…        NA      85.4      234.    14214.      26.0\n2 -67.0 -0.121 São Gab… Myris…        NA      85.4      234.    14214.      26.0\n3 -67.0 -0.121 São Gab… Myris…        NA      85.4      234.    14214.      26.0\n4 -67.0 -0.121 São Gab… Myris…        NA      85.4      234.    14214.      26.0\n5 -67.0 -0.121 São Gab… Myris…        NA      85.4      234.    14214.      26.0\n6 -66.9 -0.041 São Gab… Burse…        NA      93.4      230.    14186.      26.1\n# ℹ 3 more variables: tmax_mean <dbl>, tmin_mean <dbl>, vapr_mean <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(amz_var_clim) #Estrutura dos dados\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [2,377 × 12] (S3: tbl_df/tbl/data.frame)\n $ x        : num [1:2377] -67 -67 -67 -67 -67 ...\n $ y        : num [1:2377] -0.121 -0.121 -0.121 -0.121 -0.121 -0.041 -0.041 -0.041 -0.041 -0.041 ...\n $ Site     : chr [1:2377] \"São Gabriel da Cachoeira\" \"São Gabriel da Cachoeira\" \"São Gabriel da Cachoeira\" \"São Gabriel da Cachoeira\" ...\n $ Family   : chr [1:2377] \"Myristicaceae\" \"Myristicaceae\" \"Myristicaceae\" \"Myristicaceae\" ...\n $ d13C_wood: num [1:2377] NA NA NA NA NA NA NA NA NA NA ...\n $ elev_mean: num [1:2377] 85.4 85.4 85.4 85.4 85.4 ...\n $ prec_mean: num [1:2377] 234 234 234 234 234 ...\n $ srad_mean: num [1:2377] 14214 14214 14214 14214 14214 ...\n $ tavg_mean: num [1:2377] 26 26 26 26 26 ...\n $ tmax_mean: num [1:2377] 30.9 30.9 30.9 30.9 30.9 ...\n $ tmin_mean: num [1:2377] 21.2 21.2 21.2 21.2 21.2 ...\n $ vapr_mean: num [1:2377] 2.88 2.88 2.88 2.88 2.88 ...\n```\n\n\n:::\n:::\n\n\n\n# 4. Preparação dos dados\n\nVamos definir a variável resposta e as covariáveis que serão utilizadas na modelagem.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Tratando NAs\nd13.amz <- amz_var_clim[!is.na(amz_var_clim$d13C_wood), ]\n\n\n# Transformar tibble em SpatVector (definindo x e y como coordenadas)\nsites <- vect(as.data.frame(d13.amz), geom = c(\"x\", \"y\"), crs = \"EPSG:4674\")\n\n#Retirando coordenadas\nd13.amz <- d13.amz %>% dplyr::select(-x, -y, -Site, -Family)\n\n#Definindo a variável resposta e covariáveis \nresposta <- d13.amz$d13C_wood\n\n#Preditoras\npreditoras <- d13.amz%>% dplyr::select(-d13C_wood)\n\n#Checando valores ausentes\nif (anyNA(preditoras)) {\n  cat(\"Warning: Missing values found in predictors. Please handle them before proceeding.\\n\")\n  print(which(is.na(predictors), arr.ind = TRUE))\n} else {\n  cat(\"No missing values found in predictors.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNo missing values found in predictors.\n```\n\n\n:::\n:::\n\n\n# 2 Ajuste dos modelos\n\n## Modelo Random Forest\n\nTrabalharemos com a Random Forest, que faz parte de uma família \nde métodos chamada Árvores de Classificação e Regressão (CART). \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Nome da variável preditora\npred.names<- names(preditoras)\n\n#Definindo a formula do modelo de regressão\nformula_rf1 <- as.formula(paste(\"d13C_wood ~\", paste(pred.names, collapse = \" + \")))\nformula_rf1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nd13C_wood ~ elev_mean + prec_mean + srad_mean + tavg_mean + tmax_mean + \n    tmin_mean + vapr_mean\n```\n\n\n:::\n\n```{.r .cell-code}\n#Modelo RF com o pacotes ramdomForest\n#Fixando a reprodutibilidade\nset_reproducibility()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", :\nnon-uniform 'Rounding' sampler used\n```\n\n\n:::\n\n```{.r .cell-code}\nrf.mod1  <- randomForest(\n  formula_rf1,\n  data = d13.amz,\n  ntree = 2000,\n  importance = TRUE,\n  keep.forest = TRUE\n)\n\nrf.mod1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\n randomForest(formula = formula_rf1, data = d13.amz, ntree = 2000,      importance = TRUE, keep.forest = TRUE) \n               Type of random forest: regression\n                     Number of trees: 2000\nNo. of variables tried at each split: 2\n\n          Mean of squared residuals: 1.236812\n                    % Var explained: 51.47\n```\n\n\n:::\n:::\n\n\nOs resultados do modelo RF com todas as variáveis sugere que mais de 51% da\nvariância é explicada. O valor de MSE ficou em torno de 1.24.\n\nVamos dar uma olhada rápida no ajuste do modelo:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Criar um data frame com Observado e Predito\ndados_plot <- data.frame(\n  Observado = d13.amz$d13C_wood,\n  Predito = rf.mod1$predicted\n)\n\n# Plotar com ggplot2\nggplot(dados_plot, aes(x = Observado, y = Predito)) +\n  geom_point(shape = 21, fill = \"white\", size = 3, color = \"black\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", size = 1) +\n  labs(\n    x = expression(\"Mensurado \"*delta^{13}*\"C\"[\"Madeira\"]),\n    y = expression(\"Predito \"*delta^{13}*\"C\"[\"Madeira\"])\n  ) +\n  theme_bw() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](03_integracao_ML_files/figure-html/plotRF-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n## Seleção inicial de variáveis\n\nAté agora, ignoramos amplamente a seleção de variáveis. Durante o desenvolvimento \ndo modelo RF faz sentido permitir que o modelo explore o máximo possível de \ncaracterísticas do conjunto de dados, para que possa descobrir as relações preditivas \nmais úteis. Porém ao mesmo tempo, o uso de conjuntos de características excessivos \nou muito redundantes pode tornar o ajuste do modelo mais desafiador. Assim, é ideal \nutilizar alguma abordagem de pré-seleção de variáveis. Diante disso, optamos por\nutilizar o algoritmo VSURF.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Convertendo as variáveis preditoras para o formato matricial (requirido pelo VSURF)\npreditoras_matrix <- as.matrix(preditoras)\n\n# Rodando VSURF para seleção de variáveis\n# Fixando a reprodutibilidade\nset_reproducibility()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", :\nnon-uniform 'Rounding' sampler used\n```\n\n\n:::\n\n```{.r .cell-code}\nvsurf_result <- VSURF::VSURF(preditoras_matrix, resposta, \n                             ntree = 500,\n                             nfor.thres = 20,\n                             nfor.interp = 100,\n                             nfor.pred = 10,\n                             nsd = 1,\n                             parallel = FALSE,\n                             verbose=FALSE)\n\n\n#Extração das variáveis selecionadas VSURF \nthreshold_vars <- names(preditoras)[vsurf_result$varselect.thres]\ninterp_vars    <- names(preditoras)[vsurf_result$varselect.interp]\npred_vars      <- names(preditoras)[vsurf_result$varselect.pred]\n\n#Print das variáveis\ncat(\"\\nVariaveis selecionadas (Threshold):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nVariaveis selecionadas (Threshold):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(threshold_vars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"vapr_mean\" \"elev_mean\" \"prec_mean\" \"tavg_mean\" \"srad_mean\" \"tmin_mean\"\n[7] \"tmax_mean\"\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"nVariaveis selecionadas (Interpretação):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnVariaveis selecionadas (Interpretação):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(interp_vars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"vapr_mean\" \"elev_mean\"\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"nVariaveis selecionadas (Predição):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnVariaveis selecionadas (Predição):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(pred_vars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"vapr_mean\" \"elev_mean\"\n```\n\n\n:::\n:::\n\n\n---\n\nO algoritmo VSURF selecionou as variáveis `vapr_mean` e `elev_mean`. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Construindo a formula\nformula_rf2 <- as.formula(paste(\"d13C_wood ~\", paste(pred_vars, collapse = \" + \")))\nformula_rf2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nd13C_wood ~ vapr_mean + elev_mean\n```\n\n\n:::\n\n```{.r .cell-code}\n#Fixando a reprodutibidade\nset_reproducibility()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", :\nnon-uniform 'Rounding' sampler used\n```\n\n\n:::\n\n```{.r .cell-code}\nrf.mod2 <- randomForest(\n  formula_rf2,\n  data = d13.amz,\n  ntree = 2000,\n  importance = TRUE,\n  keep.forest = TRUE\n)\n\nrf.mod2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\n randomForest(formula = formula_rf2, data = d13.amz, ntree = 2000,      importance = TRUE, keep.forest = TRUE) \n               Type of random forest: regression\n                     Number of trees: 2000\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 1.236135\n                    % Var explained: 51.5\n```\n\n\n:::\n\n```{.r .cell-code}\n#Plot error OOB  vs número de árvores\nplot(rf.mod2, main = \"OOB Error vs Number of Trees\")\n```\n\n::: {.cell-output-display}\n![](03_integracao_ML_files/figure-html/rfVSURF-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n## Ajuste de Hiperparâmetros\n\nNo modelo RF o principal parâmetro é o `mtry` determina quantas características diferentes são\nconsideradas na seleção da regra de decisão em cada nó.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrf.tune <- caret::train(formula_rf2,\n                        data = d13.amz,\n                        ntree = 500)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnote: only 1 unique complexity parameters in default grid. Truncating the grid to 1 .\n```\n\n\n:::\n\n```{.r .cell-code}\nrf.tune$results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mtry     RMSE  Rsquared       MAE    RMSESD RsquaredSD      MAESD\n1    2 1.160945 0.4827495 0.8964839 0.0292025 0.02564418 0.01706073\n```\n\n\n:::\n\n```{.r .cell-code}\nrf.tune$bestTune\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mtry\n1    2\n```\n\n\n:::\n:::\n\n\n\nOs melhores resultados são obtidos usando o menor valor de `mtry` (2). Esse é \no valor que teria sido escolhido por padrão pela função `randomForest()`, \nportanto, aceitar o valor padrão para esse hiperparâmetro é adequado neste caso.\n\n\n## Teste\n\n Um teste simples de divisão de dados é fácil de realizar.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fixando a reprodutibilidade\nset_reproducibility()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", :\nnon-uniform 'Rounding' sampler used\n```\n\n\n:::\n\n```{.r .cell-code}\npartition <- caret::createDataPartition(d13.amz$d13C_wood, p = 0.8, list = FALSE)\ntreino <- d13.amz[partition, ]\nteste <- d13.amz[-partition, ]\n\n# AJustando o modelo com dados de treino\nrf.train <-  randomForest(formula_rf2, data = treino, ntree = 500)\nrf.train\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\n randomForest(formula = formula_rf2, data = treino, ntree = 500) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 1.243762\n                    % Var explained: 49.72\n```\n\n\n:::\n\n```{.r .cell-code}\n# Data frame Observado x Predito\ndados_plot2 <- data.frame(\n  Observado = teste$d13C_wood,\n  Predito = predict(rf.train, teste)\n)\n\n# Calcular MSE\nMSE_value <- mean((dados_plot2$Predito - dados_plot2$Observado)^2)\nMSE_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.359474\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calcular R2\nR2_value<- (cor(dados_plot2$Observado, dados_plot2$Predito))^2\nR2_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5227402\n```\n\n\n:::\n\n```{.r .cell-code}\n# ggplot com anotação\nggplot(dados_plot2, aes(x = Observado, y = Predito)) +\n  geom_point(shape = 21, fill = \"white\", size = 3, color = \"black\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = expression(\"Mensurado \"*delta^{13}*\"C\"[\"Madeira\"]),\n    y = expression(\"Predito \"*delta^{13}*\"C\"[\"Madeira\"])\n  ) +\n  annotate(\"text\",\n           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),\n           y = min(dados_plot$Predito) + 0.05 * diff(range(dados_plot$Predito)),\n           label = paste0(\"MSE = \", round(MSE_value, 2)),\n           hjust = 1, vjust = 0, size = 5) +\n  annotate(\"text\",\n           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),\n           y = min(dados_plot$Predito) + 0.2 * diff(range(dados_plot$Predito)),\n           label = paste0(\"R2 = \", round(R2_value, 2)),\n           hjust = 1, vjust = 0, size = 5) +\n  theme_bw() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12)\n  )\n```\n\n::: {.cell-output-display}\n![](03_integracao_ML_files/figure-html/splitData-1.png){fig-align='center' width=480}\n:::\n:::\n\n\nO código abaixo é uma ligeira modificação do que usamos acima e usa o\nobjeto `fitControl` para direcionar a função `train()` para realizar o que \nchamamos de validação cruzada. Para isso, optamos por utilizar o método \nLeave-Group-Out CV (também conhecido como Monte Carlo CV).\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Leave-Group-Out CV (também conhecido como Monte Carlo CV).\nfitControl <- caret::trainControl(method = \"LGOCV\", number = 10, p = 0.8)\n\n# Fixando a reprodutibidade\nset_reproducibility()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", :\nnon-uniform 'Rounding' sampler used\n```\n\n\n:::\n\n```{.r .cell-code}\nrf.mod3 <-caret::train(formula_rf2,\n                  data= d13.amz, method=\"rf\",\n                  trControl=fitControl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnote: only 1 unique complexity parameters in default grid. Truncating the grid to 1 .\n```\n\n\n:::\n\n```{.r .cell-code}\nrf.mod3$resample\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       RMSE  Rsquared       MAE   Resample\n1  1.149235 0.5106406 0.8802398 Resample01\n2  1.101808 0.5325317 0.8458073 Resample02\n3  1.125263 0.4976527 0.8877128 Resample03\n4  1.130263 0.5332018 0.8729268 Resample04\n5  1.175355 0.4315554 0.9107540 Resample05\n6  1.045588 0.5378004 0.8140918 Resample06\n7  1.177652 0.4951679 0.8847128 Resample07\n8  1.089666 0.5014897 0.8417173 Resample08\n9  1.122660 0.5048356 0.8553535 Resample09\n10 1.109617 0.5003988 0.8544265 Resample10\n```\n\n\n:::\n\n```{.r .cell-code}\nrf.mod3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest \n\n2069 samples\n   2 predictor\n\nNo pre-processing\nResampling: Repeated Train/Test Splits Estimated (10 reps, 80%) \nSummary of sample sizes: 1657, 1657, 1657, 1657, 1657, 1657, ... \nResampling results:\n\n  RMSE      Rsquared   MAE      \n  1.122711  0.5045275  0.8647743\n\nTuning parameter 'mtry' was held constant at a value of 2\n```\n\n\n:::\n:::\n\n\n\nObtemos um conjunto de métricas ligeiramente diferente aqui, mas elas são muito semelhantes às obtidas em nosso teste de dados com divisão única. A otimização e o teste de modelos de ML são um tema vasto. Para obter mais informações e exemplos de diferentes abordagens que podem ser aplicadas na modelagem CART, há um excelente texto online que acompanha o [pacote caret](https://topepo.github.io/caret/index.html).\n\n\n\n## Compreendendo o modelo\n\nEntender os modelos de ML (também chamados de *ML interpretável*) também é um tema vasto e em constante desenvolvimento, mas existem algumas ferramentas simples que podem nos ajudar a começar a entender como nosso modelo está se comportando. \n\nVeja o gráfico de importância das variáveis, que mostra basicamente o que seu nome sugere.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvarImpPlot(rf.mod3$finalModel,main='Variable Importance Plot: Base Model')\n```\n\n::: {.cell-output-display}\n![](03_integracao_ML_files/figure-html/VIP-1.png){fig-align='center' width=480}\n:::\n\n```{.r .cell-code}\nimp<-varImp(rf.mod3$finalModel)\nimp$varnames <- rownames(imp) # row names to column\nrownames(imp) <- NULL  \n\nimp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Overall  varnames\n1 2422.1897 vapr_mean\n2  980.2558 elev_mean\n```\n\n\n:::\n:::\n\n\nObserva-se que a variável ``vapr_mean`` tem o maior impacto para δ13C da madeira.\n\n\n# Isoscape\n\nNessa etapa, vamos recuperar os arquivos raster gerados na primeira etapa e criar um único raster multicamada, que será utilizado para realizar a predição espacial com a função `predict` do pacote `terra`.\n\n---\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Listar todos os arquivos raster na pasta 'raster/' \nraster_files <- list.files(path = here(\"raster\"), pattern = '\\\\.tif$', full.names = TRUE)  \n\n# Carregar todos os rasters em uma lista \n# terra ->> para carregar cada arquivo raster\nraster_list <- lapply(raster_files, terra::rast)  \nraster_list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\nclass       : SpatRaster \ndimensions  : 279, 386, 1  (nrow, ncol, nlyr)\nresolution  : 0.08333333, 0.08333333  (x, y)\nextent      : -74, -41.83333, -18, 5.25  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat SIRGAS 2000 (EPSG:4674) \nsource      : elev_mean.tif \nname        : mean \nmin value   :    0 \nmax value   : 1790 \n\n[[2]]\nclass       : SpatRaster \ndimensions  : 279, 386, 1  (nrow, ncol, nlyr)\nresolution  : 0.08333333, 0.08333333  (x, y)\nextent      : -74, -41.83333, -18, 5.25  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat SIRGAS 2000 (EPSG:4674) \nsource      : prec_mean.tif \nname        :      mean \nmin value   :  81.33334 \nmax value   : 320.08334 \n\n[[3]]\nclass       : SpatRaster \ndimensions  : 279, 386, 1  (nrow, ncol, nlyr)\nresolution  : 0.08333333, 0.08333333  (x, y)\nextent      : -74, -41.83333, -18, 5.25  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat SIRGAS 2000 (EPSG:4674) \nsource      : srad_mean.tif \nname        :    mean \nmin value   : 13109.0 \nmax value   : 18632.5 \n\n[[4]]\nclass       : SpatRaster \ndimensions  : 279, 386, 1  (nrow, ncol, nlyr)\nresolution  : 0.08333333, 0.08333333  (x, y)\nextent      : -74, -41.83333, -18, 5.25  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat SIRGAS 2000 (EPSG:4674) \nsource      : tavg_mean.tif \nname        :     mean \nmin value   : 18.63950 \nmax value   : 27.97333 \n\n[[5]]\nclass       : SpatRaster \ndimensions  : 279, 386, 1  (nrow, ncol, nlyr)\nresolution  : 0.08333333, 0.08333333  (x, y)\nextent      : -74, -41.83333, -18, 5.25  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat SIRGAS 2000 (EPSG:4674) \nsource      : tmax_mean.tif \nname        :     mean \nmin value   : 23.32775 \nmax value   : 33.43042 \n\n[[6]]\nclass       : SpatRaster \ndimensions  : 279, 386, 1  (nrow, ncol, nlyr)\nresolution  : 0.08333333, 0.08333333  (x, y)\nextent      : -74, -41.83333, -18, 5.25  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat SIRGAS 2000 (EPSG:4674) \nsource      : tmin_mean.tif \nname        :     mean \nmin value   : 13.40108 \nmax value   : 24.12500 \n\n[[7]]\nclass       : SpatRaster \ndimensions  : 279, 386, 1  (nrow, ncol, nlyr)\nresolution  : 0.08333333, 0.08333333  (x, y)\nextent      : -74, -41.83333, -18, 5.25  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat SIRGAS 2000 (EPSG:4674) \nsource      : vapr_mean.tif \nname        :     mean \nmin value   : 1.771100 \nmax value   : 3.021675 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Empilhar os rasters em um único objeto SpatRaster\n# terra ->> para empilhar todos os rasters em um único objeto\nr_stack <- terra::rast(raster_list)  \n\n# Verificar os nomes dos rasters \nnames(r_stack) <- basename(raster_files) %>% tools::file_path_sans_ext()  \nprint(names(r_stack))  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"elev_mean\" \"prec_mean\" \"srad_mean\" \"tavg_mean\" \"tmax_mean\" \"tmin_mean\"\n[7] \"vapr_mean\"\n```\n\n\n:::\n\n```{.r .cell-code}\nclass(r_stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n```\n\n\n:::\n:::\n\n## Predição \n\nFinalmente, utilizaremos a nossa melhor predição do modelo RF para construir um mapa espacial\ndo `d13C_wood`.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#Predição\nisoscape <- terra::predict(r_stack, rf.mod3, na.rm = TRUE)\n```\n:::\n\n\n\n## Calculando os desvio padrão da isoscape\n\nPara o cáculo do desvio padrão utilizaremos a seguinte expressão:\n\n$$ SD \\approx \\frac{Q_{0.84} - Q_{0.16}}{2} $$\nAssim, obtemos uma estimativa consistente de SD espacial (incerteza) a partir do intervalo central de 68% das predições do modelo QRF.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Usando o pacote \"ranger\".\n# Set reproducibility\nset_reproducibility()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", :\nnon-uniform 'Rounding' sampler used\n```\n\n\n:::\n\n```{.r .cell-code}\nmod.qrf <- ranger::ranger(formula_rf2, data=d13.amz, num.trees = 500, quantreg = TRUE)\nmod.qrf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger::ranger(formula_rf2, data = d13.amz, num.trees = 500,      quantreg = TRUE) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      2069 \nNumber of independent variables:  2 \nMtry:                             1 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       1.237437 \nR squared (OOB):                  0.5147219 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Quantis ~ ±1 DP (68%)\nisoscape$ci.16 <- terra::predict(r_stack, mod.qrf, type = \"quantiles\", quantiles = 0.16,\n                        na.rm = TRUE)\nisoscape$ci.84 <- terra::predict(r_stack, mod.qrf, type = \"quantiles\", quantiles = 0.84,\n                        na.rm = TRUE)\n\n# SD aproximado a partir de Q0.84 - Q0.16\nisoscape$sd <- (isoscape$ci.84 - isoscape$ci.16) / 2\n```\n:::\n\n\nExportando os mapas gerados.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Verificar e criar diretório para salvar os rasters, se não existir\nif (!dir.exists(here(\"isoscape\"))) dir.create(here(\"isoscape\"))\n\n#Exportando raster\nisoscape.d13c <- c(isoscape$lyr1, isoscape$sd)\n\nterra::writeRaster(isoscape.d13c, filename = here(\"isoscape\", \"isoscape_dc13.tif\"), overwrite = TRUE)\n```\n:::\n\n\n---\n\nVejamos um plot simples da Isoscape gerada pela nossa predição.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizar a isoscape\nterra::plot(isoscape[[1]], main = \"δ13C\")\n# Adicionar os pontos amostrais\npoints(sites, pch = 21, bg = \"yellow\", cex = 0.8)\n```\n\n::: {.cell-output-display}\n![](03_integracao_ML_files/figure-html/plotIsoscape-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Visualizar a isoscape\nterra::plot(isoscape$sd, main = \"SD\")\n# Adicionar os pontos amostrais\npoints(sites, pch = 21, bg = \"yellow\", cex = 0.8)\n```\n\n::: {.cell-output-display}\n![](03_integracao_ML_files/figure-html/plotIsoscapeSD-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n\n",
    "supporting": [
      "03_integracao_ML_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}