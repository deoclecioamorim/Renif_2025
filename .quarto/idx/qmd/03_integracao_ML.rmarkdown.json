{"title":"Integração com modelos de Machine Learning","markdown":{"yaml":{"title":"Integração com modelos de Machine Learning","author":"Deoclecio J. Amorim (CENA), João Paulo Sena-Souza (Unimontes) e Paulo José Duarte Neto (UFRPE)","format":{"html":{"page-layout":"full","toc":true,"toc-location":"left","fig-width":5,"fig-height":5}},"knitr":{"opts_chunk":{"fig-align":"center"}}},"headingText":"Ajuste global para gráficos","containsRefs":false,"markdown":"\n\n```{r}\n#| include: false\n\nlibrary(knitr)\nopts_knit$set(global.par = TRUE)\npar(mar = c(5, 5, 1, 1))\n\n```\n\n# Introdução \n\nNeste módulo, aprenderemos a integrar dados geoespaciais com modelos de **Machine Learning** para gerar mapas preditivos (isoscapes).\n\nO objetivo aqui é mostrar como **aprendizado de máquina, como Random Forest**, pode ser usado para mais eficientes para prever padrões espaciais de isótopos.\n\nDurante o exercício, você irá:\n\n- Preparar dados de amostras combinados com covariáveis ambientais;\n- Ajustar modelos de machine learning, por exemplo, o modelo **Random Forest**;\n- Avaliar a importância das variáveis no modelo;\n- Gerar um **mapa preditivo espacial** do δ13C.\n\n\n\n---\n\n\n# 1. Configuração inicial\n\n```{r config}\n# Limpar área de trabalho\nrm(list = ls())      \ngc(reset = TRUE)     \ngraphics.off()       \n\n#Pacotes necessários\nif(!require(readxl))install.packages(\"readxl\", dep = TRUE, quiet = TRUE)\nif(!require(tidyverse))install.packages(\"tidyverse\", dep = TRUE, quiet = TRUE)\nif(!require(terra))install.packages(\"terra\", dep = TRUE, quiet = TRUE)\nif(!require(geodata))install.packages(\"geodata\", dep = TRUE, quiet = TRUE)\nif(!require(geobr))install.packages(\"geobr\", dep = TRUE, quiet = TRUE)\nif(!require(sf))install.packages(\"sf\", dep = TRUE, quiet = TRUE)\nif(!require(sp))install.packages(\"sp\", dep = TRUE, quiet = TRUE)\nif(!require(here))install.packages(\"here\", dep = TRUE, quiet = TRUE)\nif(!require(caret))install.packages(\"caret\", dep = TRUE, quiet = TRUE)\nif(!require(randomForest))install.packages(\"randomForest\", dep = TRUE, quiet = TRUE)\nif(!require(ranger))install.packages(\"ranger\", dep = TRUE, quiet = TRUE)\nif(!require(VSURF))install.packages(\"VSURF\", dep = TRUE, quiet = TRUE)\n\n\n```\n\n# 2. Reprodutibilidade \n\nA reprodutibilidade é um princípio fundamental da ciência, pois garante que os resultados obtidos em uma pesquisa possam ser verificados e replicados por outros pesquisadores ou em futuras análises. Assegurar que os procedimentos sejam replicáveis aumenta a transparência, a credibilidade dos dados e fortalece a robustez das conclusões.\n\n\n```{r seed}\nset_reproducibility <- function(seed = 1350) {\n  set.seed(seed)\n  RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", sample.kind = \"Rounding\")\n}\n\n# Fixando a reprodutibilidade\nset_reproducibility()\n```\n\n# 3. Carregando o conjunto de dados \n\n```{r importacao_dados}\namz_var_clim <- readxl::read_excel(here::here(\"dados\", \"madeira_amz_var_clim.xlsx\"), sheet = 1)\nhead(amz_var_clim) #leitura das primeiras 6 linhas\nstr(amz_var_clim) #Estrutura dos dados\n\n```\n\n\n# 4. Preparação dos dados\n\nVamos definir a variável resposta e as covariáveis que serão utilizadas na modelagem.\n\n```{r resp_covar}\n\n#Tratando NAs\nd13.amz <- amz_var_clim[!is.na(amz_var_clim$d13C_wood), ]\n\n\n# Transformar tibble em SpatVector (definindo x e y como coordenadas)\nsites <- vect(as.data.frame(d13.amz), geom = c(\"x\", \"y\"), crs = \"EPSG:4674\")\n\n#Retirando coordenadas\nd13.amz <- d13.amz %>% dplyr::select(-x, -y, -Site, -Family)\n\n#Definindo a variável resposta e covariáveis \nresposta <- d13.amz$d13C_wood\n\n#Preditoras\npreditoras <- d13.amz%>% dplyr::select(-d13C_wood)\n\n#Checando valores ausentes\nif (anyNA(preditoras)) {\n  cat(\"Warning: Missing values found in predictors. Please handle them before proceeding.\\n\")\n  print(which(is.na(predictors), arr.ind = TRUE))\n} else {\n  cat(\"No missing values found in predictors.\\n\")\n}\n\n\n```\n\n# 2 Ajuste dos modelos\n\n## Modelo Random Forest\n\nTrabalharemos com a Random Forest, que faz parte de uma família \nde métodos chamada Árvores de Classificação e Regressão (CART). \n\n```{r rf1}\n#Nome da variável preditora\npred.names<- names(preditoras)\n\n#Definindo a formula do modelo de regressão\nformula_rf1 <- as.formula(paste(\"d13C_wood ~\", paste(pred.names, collapse = \" + \")))\nformula_rf1\n\n#Modelo RF com o pacotes ramdomForest\n#Fixando a reprodutibilidade\nset_reproducibility()\n\nrf.mod1  <- randomForest(\n  formula_rf1,\n  data = d13.amz,\n  ntree = 2000,\n  importance = TRUE,\n  keep.forest = TRUE\n)\n\nrf.mod1\n\n```\n\nOs resultados do modelo RF com todas as variáveis sugere que mais de 51% da\nvariância é explicada. O valor de MSE ficou em torno de 1.24.\n\nVamos dar uma olhada rápida no ajuste do modelo:\n\n\n```{r plotRF}\n\n# Criar um data frame com Observado e Predito\ndados_plot <- data.frame(\n  Observado = d13.amz$d13C_wood,\n  Predito = rf.mod1$predicted\n)\n\n# Plotar com ggplot2\nggplot(dados_plot, aes(x = Observado, y = Predito)) +\n  geom_point(shape = 21, fill = \"white\", size = 3, color = \"black\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", size = 1) +\n  labs(\n    x = expression(\"Mensurado \"*delta^{13}*\"C\"[\"Madeira\"]),\n    y = expression(\"Predito \"*delta^{13}*\"C\"[\"Madeira\"])\n  ) +\n  theme_bw() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12))\n\n```\n\n\n## Seleção inicial de variáveis\n\nAté agora, ignoramos amplamente a seleção de variáveis. Durante o desenvolvimento \ndo modelo RF faz sentido permitir que o modelo explore o máximo possível de \ncaracterísticas do conjunto de dados, para que possa descobrir as relações preditivas \nmais úteis. Porém ao mesmo tempo, o uso de conjuntos de características excessivos \nou muito redundantes pode tornar o ajuste do modelo mais desafiador. Assim, é ideal \nutilizar alguma abordagem de pré-seleção de variáveis. Diante disso, optamos por\nutilizar o algoritmo VSURF.\n\n\n```{r vsurf}\n\n# Convertendo as variáveis preditoras para o formato matricial (requirido pelo VSURF)\npreditoras_matrix <- as.matrix(preditoras)\n\n# Rodando VSURF para seleção de variáveis\n# Fixando a reprodutibilidade\nset_reproducibility()\n\nvsurf_result <- VSURF::VSURF(preditoras_matrix, resposta, \n                             ntree = 500,\n                             nfor.thres = 20,\n                             nfor.interp = 100,\n                             nfor.pred = 10,\n                             nsd = 1,\n                             parallel = FALSE,\n                             verbose=FALSE)\n\n\n#Extração das variáveis selecionadas VSURF \nthreshold_vars <- names(preditoras)[vsurf_result$varselect.thres]\ninterp_vars    <- names(preditoras)[vsurf_result$varselect.interp]\npred_vars      <- names(preditoras)[vsurf_result$varselect.pred]\n\n#Print das variáveis\ncat(\"\\nVariaveis selecionadas (Threshold):\\n\")\nprint(threshold_vars)\n\ncat(\"nVariaveis selecionadas (Interpretação):\\n\")\nprint(interp_vars)\n\ncat(\"nVariaveis selecionadas (Predição):\\n\")\nprint(pred_vars)\n\n\n```\n\n---\n\nO algoritmo VSURF selecionou as variáveis `vapr_mean` e `elev_mean`. \n\n\n```{r rfVSURF}\n\n#Construindo a formula\nformula_rf2 <- as.formula(paste(\"d13C_wood ~\", paste(pred_vars, collapse = \" + \")))\nformula_rf2\n\n#Fixando a reprodutibidade\nset_reproducibility()\n\nrf.mod2 <- randomForest(\n  formula_rf2,\n  data = d13.amz,\n  ntree = 2000,\n  importance = TRUE,\n  keep.forest = TRUE\n)\n\nrf.mod2\n\n#Plot error OOB  vs número de árvores\nplot(rf.mod2, main = \"OOB Error vs Number of Trees\")\n\n```\n\n## Ajuste de Hiperparâmetros\n\nNo modelo RF o principal parâmetro é o `mtry` determina quantas características diferentes são\nconsideradas na seleção da regra de decisão em cada nó.\n\n\n```{r tune}\n\nrf.tune <- caret::train(formula_rf2,\n                        data = d13.amz,\n                        ntree = 500)\nrf.tune$results\nrf.tune$bestTune\n\n```\n\n\nOs melhores resultados são obtidos usando o menor valor de `mtry` (2). Esse é \no valor que teria sido escolhido por padrão pela função `randomForest()`, \nportanto, aceitar o valor padrão para esse hiperparâmetro é adequado neste caso.\n\n\n## Teste\n\n Um teste simples de divisão de dados é fácil de realizar.\n\n\n```{r splitData}\n\n# Fixando a reprodutibilidade\nset_reproducibility()\npartition <- caret::createDataPartition(d13.amz$d13C_wood, p = 0.8, list = FALSE)\ntreino <- d13.amz[partition, ]\nteste <- d13.amz[-partition, ]\n\n# AJustando o modelo com dados de treino\nrf.train <-  randomForest(formula_rf2, data = treino, ntree = 500)\nrf.train\n\n# Data frame Observado x Predito\ndados_plot2 <- data.frame(\n  Observado = teste$d13C_wood,\n  Predito = predict(rf.train, teste)\n)\n\n# Calcular MSE\nMSE_value <- mean((dados_plot2$Predito - dados_plot2$Observado)^2)\nMSE_value\n\n# Calcular R2\nR2_value<- (cor(dados_plot2$Observado, dados_plot2$Predito))^2\nR2_value\n\n# ggplot com anotação\nggplot(dados_plot2, aes(x = Observado, y = Predito)) +\n  geom_point(shape = 21, fill = \"white\", size = 3, color = \"black\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = expression(\"Mensurado \"*delta^{13}*\"C\"[\"Madeira\"]),\n    y = expression(\"Predito \"*delta^{13}*\"C\"[\"Madeira\"])\n  ) +\n  annotate(\"text\",\n           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),\n           y = min(dados_plot$Predito) + 0.05 * diff(range(dados_plot$Predito)),\n           label = paste0(\"MSE = \", round(MSE_value, 2)),\n           hjust = 1, vjust = 0, size = 5) +\n  annotate(\"text\",\n           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),\n           y = min(dados_plot$Predito) + 0.2 * diff(range(dados_plot$Predito)),\n           label = paste0(\"R2 = \", round(R2_value, 2)),\n           hjust = 1, vjust = 0, size = 5) +\n  theme_bw() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12)\n  )\n\n\n```\n\nO código abaixo é uma ligeira modificação do que usamos acima e usa o\nobjeto `fitControl` para direcionar a função `train()` para realizar o que \nchamamos de validação cruzada. Para isso, optamos por utilizar o método \nLeave-Group-Out CV (também conhecido como Monte Carlo CV).\n\n\n```{r CV}\n\n# Leave-Group-Out CV (também conhecido como Monte Carlo CV).\nfitControl <- caret::trainControl(method = \"LGOCV\", number = 10, p = 0.8)\n\n# Fixando a reprodutibidade\nset_reproducibility()\nrf.mod3 <-caret::train(formula_rf2,\n                  data= d13.amz, method=\"rf\",\n                  trControl=fitControl)\n\n\nrf.mod3$resample\nrf.mod3\n\n\n\n```\n\n\nObtemos um conjunto de métricas ligeiramente diferente aqui, mas elas são muito semelhantes às obtidas em nosso teste de dados com divisão única. A otimização e o teste de modelos de ML são um tema vasto. Para obter mais informações e exemplos de diferentes abordagens que podem ser aplicadas na modelagem CART, há um excelente texto online que acompanha o [pacote caret](https://topepo.github.io/caret/index.html).\n\n\n\n## Compreendendo o modelo\n\nEntender os modelos de ML (também chamados de *ML interpretável*) também é um tema vasto e em constante desenvolvimento, mas existem algumas ferramentas simples que podem nos ajudar a começar a entender como nosso modelo está se comportando. \n\nVeja o gráfico de importância das variáveis, que mostra basicamente o que seu nome sugere.\n\n\n\n```{r VIP}\nvarImpPlot(rf.mod3$finalModel,main='Variable Importance Plot: Base Model')\n\nimp<-varImp(rf.mod3$finalModel)\nimp$varnames <- rownames(imp) # row names to column\nrownames(imp) <- NULL  \n\nimp\n\n```\n\nObserva-se que a variável ``vapr_mean`` tem o maior impacto para δ13C da madeira.\n\n\n# Isoscape\n\nNessa etapa, vamos recuperar os arquivos raster gerados na primeira etapa e criar um único raster multicamada, que será utilizado para realizar a predição espacial com a função `predict` do pacote `terra`.\n\n---\n\n```{r predEspacial}\n# Listar todos os arquivos raster na pasta 'raster/' \nraster_files <- list.files(path = here(\"raster\"), pattern = '\\\\.tif$', full.names = TRUE)  \n\n# Carregar todos os rasters em uma lista \n# terra ->> para carregar cada arquivo raster\nraster_list <- lapply(raster_files, terra::rast)  \nraster_list\n\n# Empilhar os rasters em um único objeto SpatRaster\n# terra ->> para empilhar todos os rasters em um único objeto\nr_stack <- terra::rast(raster_list)  \n\n# Verificar os nomes dos rasters \nnames(r_stack) <- basename(raster_files) %>% tools::file_path_sans_ext()  \nprint(names(r_stack))  \nclass(r_stack)\n\n```\n## Predição \n\nFinalmente, utilizaremos a nossa melhor predição do modelo RF para construir um mapa espacial\ndo `d13C_wood`.  \n\n```{r isoscape}\n#Predição\nisoscape <- terra::predict(r_stack, rf.mod3, na.rm = TRUE)\n\n```\n\n\n## Calculando os desvio padrão da isoscape\n\nPara o cáculo do desvio padrão utilizaremos a seguinte expressão:\n\n$$ SD \\approx \\frac{Q_{0.84} - Q_{0.16}}{2} $$\nAssim, obtemos uma estimativa consistente de SD espacial (incerteza) a partir do intervalo central de 68% das predições do modelo QRF.\n\n```{r}\n\n# Usando o pacote \"ranger\".\n# Set reproducibility\nset_reproducibility()\nmod.qrf <- ranger::ranger(formula_rf2, data=d13.amz, num.trees = 500, quantreg = TRUE)\nmod.qrf\n\n# Quantis ~ ±1 DP (68%)\nisoscape$ci.16 <- terra::predict(r_stack, mod.qrf, type = \"quantiles\", quantiles = 0.16,\n                        na.rm = TRUE)\nisoscape$ci.84 <- terra::predict(r_stack, mod.qrf, type = \"quantiles\", quantiles = 0.84,\n                        na.rm = TRUE)\n\n# SD aproximado a partir de Q0.84 - Q0.16\nisoscape$sd <- (isoscape$ci.84 - isoscape$ci.16) / 2\n\n```\n\nExportando os mapas gerados.\n\n```{r}\n# Verificar e criar diretório para salvar os rasters, se não existir\nif (!dir.exists(here(\"isoscape\"))) dir.create(here(\"isoscape\"))\n\n#Exportando raster\nisoscape.d13c <- c(isoscape$lyr1, isoscape$sd)\n\nterra::writeRaster(isoscape.d13c, filename = here(\"isoscape\", \"isoscape_dc13.tif\"), overwrite = TRUE)\n\n```\n\n---\n\nVejamos um plot simples da Isoscape gerada pela nossa predição.\n\n```{r plotIsoscape}\n# Visualizar a isoscape\nterra::plot(isoscape[[1]], main = \"δ13C\")\n# Adicionar os pontos amostrais\npoints(sites, pch = 21, bg = \"yellow\", cex = 0.8)\n\n```\n\n```{r plotIsoscapeSD}\n# Visualizar a isoscape\nterra::plot(isoscape$sd, main = \"SD\")\n# Adicionar os pontos amostrais\npoints(sites, pch = 21, bg = \"yellow\", cex = 0.8)\n\n```\n\n\n\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| include: false\n\n# Ajuste global para gráficos\nlibrary(knitr)\nopts_knit$set(global.par = TRUE)\npar(mar = c(5, 5, 1, 1))\n\n```\n\n# Introdução \n\nNeste módulo, aprenderemos a integrar dados geoespaciais com modelos de **Machine Learning** para gerar mapas preditivos (isoscapes).\n\nO objetivo aqui é mostrar como **aprendizado de máquina, como Random Forest**, pode ser usado para mais eficientes para prever padrões espaciais de isótopos.\n\nDurante o exercício, você irá:\n\n- Preparar dados de amostras combinados com covariáveis ambientais;\n- Ajustar modelos de machine learning, por exemplo, o modelo **Random Forest**;\n- Avaliar a importância das variáveis no modelo;\n- Gerar um **mapa preditivo espacial** do δ13C.\n\n\n\n---\n\n\n# 1. Configuração inicial\n\n```{r config}\n# Limpar área de trabalho\nrm(list = ls())      \ngc(reset = TRUE)     \ngraphics.off()       \n\n#Pacotes necessários\nif(!require(readxl))install.packages(\"readxl\", dep = TRUE, quiet = TRUE)\nif(!require(tidyverse))install.packages(\"tidyverse\", dep = TRUE, quiet = TRUE)\nif(!require(terra))install.packages(\"terra\", dep = TRUE, quiet = TRUE)\nif(!require(geodata))install.packages(\"geodata\", dep = TRUE, quiet = TRUE)\nif(!require(geobr))install.packages(\"geobr\", dep = TRUE, quiet = TRUE)\nif(!require(sf))install.packages(\"sf\", dep = TRUE, quiet = TRUE)\nif(!require(sp))install.packages(\"sp\", dep = TRUE, quiet = TRUE)\nif(!require(here))install.packages(\"here\", dep = TRUE, quiet = TRUE)\nif(!require(caret))install.packages(\"caret\", dep = TRUE, quiet = TRUE)\nif(!require(randomForest))install.packages(\"randomForest\", dep = TRUE, quiet = TRUE)\nif(!require(ranger))install.packages(\"ranger\", dep = TRUE, quiet = TRUE)\nif(!require(VSURF))install.packages(\"VSURF\", dep = TRUE, quiet = TRUE)\n\n\n```\n\n# 2. Reprodutibilidade \n\nA reprodutibilidade é um princípio fundamental da ciência, pois garante que os resultados obtidos em uma pesquisa possam ser verificados e replicados por outros pesquisadores ou em futuras análises. Assegurar que os procedimentos sejam replicáveis aumenta a transparência, a credibilidade dos dados e fortalece a robustez das conclusões.\n\n\n```{r seed}\nset_reproducibility <- function(seed = 1350) {\n  set.seed(seed)\n  RNGkind(kind = \"Mersenne-Twister\", normal.kind = \"Inversion\", sample.kind = \"Rounding\")\n}\n\n# Fixando a reprodutibilidade\nset_reproducibility()\n```\n\n# 3. Carregando o conjunto de dados \n\n```{r importacao_dados}\namz_var_clim <- readxl::read_excel(here::here(\"dados\", \"madeira_amz_var_clim.xlsx\"), sheet = 1)\nhead(amz_var_clim) #leitura das primeiras 6 linhas\nstr(amz_var_clim) #Estrutura dos dados\n\n```\n\n\n# 4. Preparação dos dados\n\nVamos definir a variável resposta e as covariáveis que serão utilizadas na modelagem.\n\n```{r resp_covar}\n\n#Tratando NAs\nd13.amz <- amz_var_clim[!is.na(amz_var_clim$d13C_wood), ]\n\n\n# Transformar tibble em SpatVector (definindo x e y como coordenadas)\nsites <- vect(as.data.frame(d13.amz), geom = c(\"x\", \"y\"), crs = \"EPSG:4674\")\n\n#Retirando coordenadas\nd13.amz <- d13.amz %>% dplyr::select(-x, -y, -Site, -Family)\n\n#Definindo a variável resposta e covariáveis \nresposta <- d13.amz$d13C_wood\n\n#Preditoras\npreditoras <- d13.amz%>% dplyr::select(-d13C_wood)\n\n#Checando valores ausentes\nif (anyNA(preditoras)) {\n  cat(\"Warning: Missing values found in predictors. Please handle them before proceeding.\\n\")\n  print(which(is.na(predictors), arr.ind = TRUE))\n} else {\n  cat(\"No missing values found in predictors.\\n\")\n}\n\n\n```\n\n# 2 Ajuste dos modelos\n\n## Modelo Random Forest\n\nTrabalharemos com a Random Forest, que faz parte de uma família \nde métodos chamada Árvores de Classificação e Regressão (CART). \n\n```{r rf1}\n#Nome da variável preditora\npred.names<- names(preditoras)\n\n#Definindo a formula do modelo de regressão\nformula_rf1 <- as.formula(paste(\"d13C_wood ~\", paste(pred.names, collapse = \" + \")))\nformula_rf1\n\n#Modelo RF com o pacotes ramdomForest\n#Fixando a reprodutibilidade\nset_reproducibility()\n\nrf.mod1  <- randomForest(\n  formula_rf1,\n  data = d13.amz,\n  ntree = 2000,\n  importance = TRUE,\n  keep.forest = TRUE\n)\n\nrf.mod1\n\n```\n\nOs resultados do modelo RF com todas as variáveis sugere que mais de 51% da\nvariância é explicada. O valor de MSE ficou em torno de 1.24.\n\nVamos dar uma olhada rápida no ajuste do modelo:\n\n\n```{r plotRF}\n\n# Criar um data frame com Observado e Predito\ndados_plot <- data.frame(\n  Observado = d13.amz$d13C_wood,\n  Predito = rf.mod1$predicted\n)\n\n# Plotar com ggplot2\nggplot(dados_plot, aes(x = Observado, y = Predito)) +\n  geom_point(shape = 21, fill = \"white\", size = 3, color = \"black\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", size = 1) +\n  labs(\n    x = expression(\"Mensurado \"*delta^{13}*\"C\"[\"Madeira\"]),\n    y = expression(\"Predito \"*delta^{13}*\"C\"[\"Madeira\"])\n  ) +\n  theme_bw() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12))\n\n```\n\n\n## Seleção inicial de variáveis\n\nAté agora, ignoramos amplamente a seleção de variáveis. Durante o desenvolvimento \ndo modelo RF faz sentido permitir que o modelo explore o máximo possível de \ncaracterísticas do conjunto de dados, para que possa descobrir as relações preditivas \nmais úteis. Porém ao mesmo tempo, o uso de conjuntos de características excessivos \nou muito redundantes pode tornar o ajuste do modelo mais desafiador. Assim, é ideal \nutilizar alguma abordagem de pré-seleção de variáveis. Diante disso, optamos por\nutilizar o algoritmo VSURF.\n\n\n```{r vsurf}\n\n# Convertendo as variáveis preditoras para o formato matricial (requirido pelo VSURF)\npreditoras_matrix <- as.matrix(preditoras)\n\n# Rodando VSURF para seleção de variáveis\n# Fixando a reprodutibilidade\nset_reproducibility()\n\nvsurf_result <- VSURF::VSURF(preditoras_matrix, resposta, \n                             ntree = 500,\n                             nfor.thres = 20,\n                             nfor.interp = 100,\n                             nfor.pred = 10,\n                             nsd = 1,\n                             parallel = FALSE,\n                             verbose=FALSE)\n\n\n#Extração das variáveis selecionadas VSURF \nthreshold_vars <- names(preditoras)[vsurf_result$varselect.thres]\ninterp_vars    <- names(preditoras)[vsurf_result$varselect.interp]\npred_vars      <- names(preditoras)[vsurf_result$varselect.pred]\n\n#Print das variáveis\ncat(\"\\nVariaveis selecionadas (Threshold):\\n\")\nprint(threshold_vars)\n\ncat(\"nVariaveis selecionadas (Interpretação):\\n\")\nprint(interp_vars)\n\ncat(\"nVariaveis selecionadas (Predição):\\n\")\nprint(pred_vars)\n\n\n```\n\n---\n\nO algoritmo VSURF selecionou as variáveis `vapr_mean` e `elev_mean`. \n\n\n```{r rfVSURF}\n\n#Construindo a formula\nformula_rf2 <- as.formula(paste(\"d13C_wood ~\", paste(pred_vars, collapse = \" + \")))\nformula_rf2\n\n#Fixando a reprodutibidade\nset_reproducibility()\n\nrf.mod2 <- randomForest(\n  formula_rf2,\n  data = d13.amz,\n  ntree = 2000,\n  importance = TRUE,\n  keep.forest = TRUE\n)\n\nrf.mod2\n\n#Plot error OOB  vs número de árvores\nplot(rf.mod2, main = \"OOB Error vs Number of Trees\")\n\n```\n\n## Ajuste de Hiperparâmetros\n\nNo modelo RF o principal parâmetro é o `mtry` determina quantas características diferentes são\nconsideradas na seleção da regra de decisão em cada nó.\n\n\n```{r tune}\n\nrf.tune <- caret::train(formula_rf2,\n                        data = d13.amz,\n                        ntree = 500)\nrf.tune$results\nrf.tune$bestTune\n\n```\n\n\nOs melhores resultados são obtidos usando o menor valor de `mtry` (2). Esse é \no valor que teria sido escolhido por padrão pela função `randomForest()`, \nportanto, aceitar o valor padrão para esse hiperparâmetro é adequado neste caso.\n\n\n## Teste\n\n Um teste simples de divisão de dados é fácil de realizar.\n\n\n```{r splitData}\n\n# Fixando a reprodutibilidade\nset_reproducibility()\npartition <- caret::createDataPartition(d13.amz$d13C_wood, p = 0.8, list = FALSE)\ntreino <- d13.amz[partition, ]\nteste <- d13.amz[-partition, ]\n\n# AJustando o modelo com dados de treino\nrf.train <-  randomForest(formula_rf2, data = treino, ntree = 500)\nrf.train\n\n# Data frame Observado x Predito\ndados_plot2 <- data.frame(\n  Observado = teste$d13C_wood,\n  Predito = predict(rf.train, teste)\n)\n\n# Calcular MSE\nMSE_value <- mean((dados_plot2$Predito - dados_plot2$Observado)^2)\nMSE_value\n\n# Calcular R2\nR2_value<- (cor(dados_plot2$Observado, dados_plot2$Predito))^2\nR2_value\n\n# ggplot com anotação\nggplot(dados_plot2, aes(x = Observado, y = Predito)) +\n  geom_point(shape = 21, fill = \"white\", size = 3, color = \"black\") +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = expression(\"Mensurado \"*delta^{13}*\"C\"[\"Madeira\"]),\n    y = expression(\"Predito \"*delta^{13}*\"C\"[\"Madeira\"])\n  ) +\n  annotate(\"text\",\n           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),\n           y = min(dados_plot$Predito) + 0.05 * diff(range(dados_plot$Predito)),\n           label = paste0(\"MSE = \", round(MSE_value, 2)),\n           hjust = 1, vjust = 0, size = 5) +\n  annotate(\"text\",\n           x = min(dados_plot$Observado) + 0.95 * diff(range(dados_plot$Observado)),\n           y = min(dados_plot$Predito) + 0.2 * diff(range(dados_plot$Predito)),\n           label = paste0(\"R2 = \", round(R2_value, 2)),\n           hjust = 1, vjust = 0, size = 5) +\n  theme_bw() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12)\n  )\n\n\n```\n\nO código abaixo é uma ligeira modificação do que usamos acima e usa o\nobjeto `fitControl` para direcionar a função `train()` para realizar o que \nchamamos de validação cruzada. Para isso, optamos por utilizar o método \nLeave-Group-Out CV (também conhecido como Monte Carlo CV).\n\n\n```{r CV}\n\n# Leave-Group-Out CV (também conhecido como Monte Carlo CV).\nfitControl <- caret::trainControl(method = \"LGOCV\", number = 10, p = 0.8)\n\n# Fixando a reprodutibidade\nset_reproducibility()\nrf.mod3 <-caret::train(formula_rf2,\n                  data= d13.amz, method=\"rf\",\n                  trControl=fitControl)\n\n\nrf.mod3$resample\nrf.mod3\n\n\n\n```\n\n\nObtemos um conjunto de métricas ligeiramente diferente aqui, mas elas são muito semelhantes às obtidas em nosso teste de dados com divisão única. A otimização e o teste de modelos de ML são um tema vasto. Para obter mais informações e exemplos de diferentes abordagens que podem ser aplicadas na modelagem CART, há um excelente texto online que acompanha o [pacote caret](https://topepo.github.io/caret/index.html).\n\n\n\n## Compreendendo o modelo\n\nEntender os modelos de ML (também chamados de *ML interpretável*) também é um tema vasto e em constante desenvolvimento, mas existem algumas ferramentas simples que podem nos ajudar a começar a entender como nosso modelo está se comportando. \n\nVeja o gráfico de importância das variáveis, que mostra basicamente o que seu nome sugere.\n\n\n\n```{r VIP}\nvarImpPlot(rf.mod3$finalModel,main='Variable Importance Plot: Base Model')\n\nimp<-varImp(rf.mod3$finalModel)\nimp$varnames <- rownames(imp) # row names to column\nrownames(imp) <- NULL  \n\nimp\n\n```\n\nObserva-se que a variável ``vapr_mean`` tem o maior impacto para δ13C da madeira.\n\n\n# Isoscape\n\nNessa etapa, vamos recuperar os arquivos raster gerados na primeira etapa e criar um único raster multicamada, que será utilizado para realizar a predição espacial com a função `predict` do pacote `terra`.\n\n---\n\n```{r predEspacial}\n# Listar todos os arquivos raster na pasta 'raster/' \nraster_files <- list.files(path = here(\"raster\"), pattern = '\\\\.tif$', full.names = TRUE)  \n\n# Carregar todos os rasters em uma lista \n# terra ->> para carregar cada arquivo raster\nraster_list <- lapply(raster_files, terra::rast)  \nraster_list\n\n# Empilhar os rasters em um único objeto SpatRaster\n# terra ->> para empilhar todos os rasters em um único objeto\nr_stack <- terra::rast(raster_list)  \n\n# Verificar os nomes dos rasters \nnames(r_stack) <- basename(raster_files) %>% tools::file_path_sans_ext()  \nprint(names(r_stack))  \nclass(r_stack)\n\n```\n## Predição \n\nFinalmente, utilizaremos a nossa melhor predição do modelo RF para construir um mapa espacial\ndo `d13C_wood`.  \n\n```{r isoscape}\n#Predição\nisoscape <- terra::predict(r_stack, rf.mod3, na.rm = TRUE)\n\n```\n\n\n## Calculando os desvio padrão da isoscape\n\nPara o cáculo do desvio padrão utilizaremos a seguinte expressão:\n\n$$ SD \\approx \\frac{Q_{0.84} - Q_{0.16}}{2} $$\nAssim, obtemos uma estimativa consistente de SD espacial (incerteza) a partir do intervalo central de 68% das predições do modelo QRF.\n\n```{r}\n\n# Usando o pacote \"ranger\".\n# Set reproducibility\nset_reproducibility()\nmod.qrf <- ranger::ranger(formula_rf2, data=d13.amz, num.trees = 500, quantreg = TRUE)\nmod.qrf\n\n# Quantis ~ ±1 DP (68%)\nisoscape$ci.16 <- terra::predict(r_stack, mod.qrf, type = \"quantiles\", quantiles = 0.16,\n                        na.rm = TRUE)\nisoscape$ci.84 <- terra::predict(r_stack, mod.qrf, type = \"quantiles\", quantiles = 0.84,\n                        na.rm = TRUE)\n\n# SD aproximado a partir de Q0.84 - Q0.16\nisoscape$sd <- (isoscape$ci.84 - isoscape$ci.16) / 2\n\n```\n\nExportando os mapas gerados.\n\n```{r}\n# Verificar e criar diretório para salvar os rasters, se não existir\nif (!dir.exists(here(\"isoscape\"))) dir.create(here(\"isoscape\"))\n\n#Exportando raster\nisoscape.d13c <- c(isoscape$lyr1, isoscape$sd)\n\nterra::writeRaster(isoscape.d13c, filename = here(\"isoscape\", \"isoscape_dc13.tif\"), overwrite = TRUE)\n\n```\n\n---\n\nVejamos um plot simples da Isoscape gerada pela nossa predição.\n\n```{r plotIsoscape}\n# Visualizar a isoscape\nterra::plot(isoscape[[1]], main = \"δ13C\")\n# Adicionar os pontos amostrais\npoints(sites, pch = 21, bg = \"yellow\", cex = 0.8)\n\n```\n\n```{r plotIsoscapeSD}\n# Visualizar a isoscape\nterra::plot(isoscape$sd, main = \"SD\")\n# Adicionar os pontos amostrais\npoints(sites, pch = 21, bg = \"yellow\", cex = 0.8)\n\n```\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":5,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"03_integracao_ML.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","title":"Integração com modelos de Machine Learning","author":"Deoclecio J. Amorim (CENA), João Paulo Sena-Souza (Unimontes) e Paulo José Duarte Neto (UFRPE)","knitr":{"opts_chunk":{"fig-align":"center"}},"page-layout":"full","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}